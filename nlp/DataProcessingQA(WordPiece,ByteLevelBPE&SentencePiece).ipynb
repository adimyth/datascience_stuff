{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataProcessingQA(WordPiece, ByteLevelBPE & SentencePiece).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPj4bE+XfnWStbBeiL/XGUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adimyth/datascience_stuff/blob/master/nlp/DataProcessingQA(WordPiece%2CByteLevelBPE%26SentencePiece).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OP_yLQDJcpu",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing (Question Answering)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGzqwy5q6G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTs9xWAIDOk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "from tokenizers import BertWordPieceTokenizer, ByteLevelBPETokenizer, SentencePieceBPETokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiQpxg6EJbHF",
        "colab_type": "text"
      },
      "source": [
        "## BERT\n",
        "\n",
        "[Kaggle Kernel](https://www.kaggle.com/akensert/tweet-bert-base-with-tf2-1-mixed-precision/comments)\n",
        "\n",
        "BERT uses Word Piece Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkrawzoVDU2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = \"Sooo SAD I will miss you here in San Diego!!!\"\n",
        "selected_text = \"Sooo SAD\"\n",
        "sentiment = \"negative\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAF1H9ND7Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_start, idx_end = None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZE7qy36D7MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index in (i for i, c in enumerate(tweet) if c == selected_text[0]):\n",
        "    if tweet[index:index+len(selected_text)] == selected_text:\n",
        "        idx_start = index\n",
        "        idx_end = index + len(selected_text)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-5D2FZbD7B-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c6eca50-4e2c-44ef-b9da-f81ef2202831"
      },
      "source": [
        "idx_start, idx_end, tweet[idx_start: idx_end]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 8, 'Sooo SAD')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP_jgiYuESbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intersection = [0]*len(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOdRA3WAESNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx in range(idx_start, idx_end):\n",
        "    intersection[idx] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqGxmnoBJKDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "165737a5-8b9f-4709-c1ed-bb1d80e5d036"
      },
      "source": [
        "print(intersection)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zdoCjGRHf_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "29862f84-64ff-4c4d-ac2b-a8621e43f0e2"
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-16 08:43:27--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.64.238\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.64.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [text/plain]\n",
            "Saving to: ‘bert-base-uncased-vocab.txt’\n",
            "\n",
            "bert-base-uncased-v 100%[===================>] 226.08K   307KB/s    in 0.7s    \n",
            "\n",
            "2020-07-16 08:43:29 (307 KB/s) - ‘bert-base-uncased-vocab.txt’ saved [231508/231508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYuKMPf_ER1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\", \n",
        "                                   lowercase=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kl_wKGoD29O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = \"Sooo SAD I will miss you here in San Diego!!! Unfortunately, he will not be coming\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMbQrH-nERuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = tokenizer.encode(tweet, add_special_tokens=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Vu6QKIDU-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bbbeefb4-3d9a-4a37-8a27-2102bb9a094f"
      },
      "source": [
        "print(f\"IDS: {enc.ids}\\n\")\n",
        "print(f\"TOKENS: {enc.tokens}\\n\")\n",
        "print(f\"OFFSET: {enc.offsets}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDS: [17111, 2080, 6517, 1045, 2097, 3335, 2017, 2182, 1999, 2624, 5277, 999, 999, 999, 6854, 1010, 2002, 2097, 2025, 2022, 2746]\n",
            "\n",
            "TOKENS: ['soo', '##o', 'sad', 'i', 'will', 'miss', 'you', 'here', 'in', 'san', 'diego', '!', '!', '!', 'unfortunately', ',', 'he', 'will', 'not', 'be', 'coming']\n",
            "\n",
            "OFFSET: [(0, 3), (3, 4), (5, 8), (9, 10), (11, 15), (16, 20), (21, 24), (25, 29), (30, 32), (33, 36), (37, 42), (42, 43), (43, 44), (44, 45), (46, 59), (59, 60), (61, 63), (64, 68), (69, 72), (73, 75), (76, 82)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOfyeUbrPcve",
        "colab_type": "text"
      },
      "source": [
        "### Calculating Offsets based on tokens\n",
        "\n",
        "Function to calculate offsets given tokens. However, it fails when token is just a single character. Example. -\n",
        "\n",
        "```\n",
        "He is studying! Oh no, he's playing!\n",
        "```\n",
        "Here, \"he's\" decomposes into \"he\", \"s\" & hence it fails when generating offset of \"s\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya-cRqgdIg7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_all_indexes(input_str, substring):\n",
        "    l2 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(substring, index)\n",
        "        if i == -1:\n",
        "            return l2\n",
        "        l2.append(i)\n",
        "        index = i + 1\n",
        "    return l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFE-2YEK_7PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "offsets = []\n",
        "counts = {} # count for repetitive words\n",
        "for idx, x in enumerate(enc.tokens):\n",
        "    y = x.strip(\"##\")       # BERT\n",
        "    if y not in counts.keys():\n",
        "        counts[y] = 0\n",
        "    else:\n",
        "        counts[y] += 1\n",
        "    o1 = find_all_indexes(tweet.lower(), y)[counts[y]]\n",
        "    if \"##\" in x:\n",
        "        o1 = offsets[idx-1][1]\n",
        "    o2 = o1+len(y)\n",
        "    offsets.append((o1, o2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "labGST6OI7RG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "266e08af-e0b4-4273-a13a-36be14121d33"
      },
      "source": [
        "print(offsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 3), (3, 4), (5, 8), (9, 10), (11, 15), (16, 20), (21, 24), (25, 29), (30, 32), (33, 36), (37, 42), (42, 43), (43, 44), (44, 45)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwmq39o1NO2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGifQdOQIIS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60758854-3f63-40ac-bfb8-623134f00e42"
      },
      "source": [
        "target_idx = []\n",
        "for i, (o1, o2) in enumerate(enc.offsets):\n",
        "    if sum(intersection[o1: o2]) > 0:\n",
        "        print(o1, o2, enc.tokens[i])\n",
        "        target_idx.append(i)\n",
        "    \n",
        "target_start = target_idx[0]\n",
        "target_end = target_idx[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3 soo\n",
            "3 4 ##o\n",
            "5 8 sad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqEqXWBMJvVC",
        "colab_type": "text"
      },
      "source": [
        "Because the selected text could contain half of the word only, so we cannot use `idx_start` & `idx_end` calculated previously. So, we recalculate to include the entire word.\n",
        "\n",
        "Try changing selected text to `Sooo SA` and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVEBHr-0IIQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5fa91ccf-8bcc-4eaa-fa86-5f23335db387"
      },
      "source": [
        "print(f\"Target start token index: {target_start}\")\n",
        "print(f\"Target end token index: {target_end}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target start token index: 0\n",
            "Target end token index: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjGPBroLxhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"bert-base-uncased-vocab.txt\", \"r\") as file:\n",
        "    vocab = [x.strip() for x in file.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx4jpeDtM1Bo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6491f16a-6be2-4e89-9927-a1cc4f7b127c"
      },
      "source": [
        "vocab[101], vocab[102], vocab[3893], vocab[4997], vocab[8699]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', '[SEP]', 'positive', 'negative', 'neutral')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW1W9q5GDU5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_map = {'positive': 3893, \n",
        "                 'negative': 4997,\n",
        "                 'neutral': 8699,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B6waDVaNPsb",
        "colab_type": "text"
      },
      "source": [
        "Bert Question Anwering has the following format -\n",
        "\n",
        "`[CLS][q1, q2, q3, ....][SEP][c1, c2, c3, ....][SEP]`\n",
        "\n",
        "* `[q1, q2, q3, ...]` are the token ids for question tokens\n",
        "* `[c1, c2, c3, ...]` are the token ids for context tokens\n",
        "* `[CLS]` - Classification token (NSP)\n",
        "* `[SEP]` - Seperator token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAX5K52aMQnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = [101] + [sentiment_map[sentiment]] + [102] + enc.ids + [102]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH_EiotkMA_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_type_ids = [0, 0, 0] + [1]*len(enc.ids) + [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx0wDJiMXSkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = [1]*(len(enc.ids)+4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuNEfGMBXY6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Offsets for [CLS] [sentiment] [SEP] followed by actual offsets & [SEP] at end\n",
        "offsets = [(0, 0), (0, 0), (0, 0)]+enc.offsets+[(0, 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbDBA7MXYvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_start += 3\n",
        "target_end += 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRNeXh36XwY0",
        "colab_type": "text"
      },
      "source": [
        "Since, we added `[CLS] [sentiment] [SEP]` before the actual `token ids` so the target start index and target end will be shifted now by 3 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwAmj8d-MBCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b189b065-6b25-4c50-9f0b-a9a3955b9c7d"
      },
      "source": [
        "print(f\"Input IDS: {input_ids}\\n\")\n",
        "print(f\"Tokens: {' '.join([vocab[i] for i in input_ids])}\\n\")\n",
        "print(f\"Input Type IDS: {input_type_ids}\\n\")\n",
        "print(f\"Offsets: {offsets}\\n\")\n",
        "print(f\"Start Target Index: {target_start}\\tEnd Target Index: {target_end}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input IDS: [101, 4997, 102, 17111, 2080, 6517, 1045, 2097, 3335, 2017, 2182, 1999, 2624, 5277, 999, 999, 999, 102]\n",
            "\n",
            "Tokens: [CLS] negative [SEP] soo ##o sad i will miss you here in san diego ! ! ! [SEP]\n",
            "\n",
            "Input Type IDS: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "\n",
            "Offsets: [(0, 0), (0, 0), (0, 0), (0, 3), (3, 4), (5, 8), (9, 10), (11, 15), (16, 20), (21, 24), (25, 29), (30, 32), (33, 36), (37, 42), (42, 43), (43, 44), (44, 45), (0, 0)]\n",
            "\n",
            "Start Target Index: 3\tEnd Target Index: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKBoeCTKZMVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 512 # hyperparameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xvrkxJuZMYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padding_length = MAX_LEN - len(enc.ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qks7dunZZRFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if padding_length > 0:\n",
        "    input_ids = input_ids+([0]*padding_length)\n",
        "    attention_mask = attention_mask+([0]*padding_length)\n",
        "    input_type_ids = input_type_ids+([0]*padding_length)\n",
        "    offsets = offsets+([(0, 0)]*padding_length)\n",
        "elif padding_length < 0:\n",
        "    # adding [SEP] token at the end\n",
        "    input_ids = input_ids[:padding_length-1]+[102]\n",
        "    attention_mask = attention_mask[:padding_length-1]+[1]\n",
        "    input_type_ids = input_type_ids[:padding_length-1]+[1]\n",
        "    offsets = offsets[:padding_length-1]+[(0, 0)]\n",
        "    if target_start >= MAX_LEN:\n",
        "        target_start = MAX_LEN - 1\n",
        "    if target_end >= MAX_LEN:\n",
        "        target_end = MAX_LEN - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMc-dQtjZRI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM9USiyWnPen",
        "colab_type": "text"
      },
      "source": [
        "## RoBERTa\n",
        "\n",
        "[Abhishek Thakur's Kernel](https://www.kaggle.com/abhishek/roberta-inference-5-folds)\n",
        "\n",
        "RoBERTa uses Byte Level Byte Pair Encoding. Also used in Open AI's GPT2 model.\n",
        "\n",
        "RoBERTa builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.\n",
        "\n",
        "RoBERTa doesn’t have `token_type_ids`, you don’t need to indicate which token belongs to which segment. Just separate your segments with the separation token `</s>`.\n",
        "\n",
        "Special tokens in RoBERTa differ from BERT -\n",
        "* `</s>` - Seperator Token, End of Seq (*eos*) token\n",
        "* `<s>` - CLS Token, Beginning of Sequence (*bos*) token\n",
        "* `<pad>` - Padding Token\n",
        "\n",
        "A RoBERTa sequence has the following format:\n",
        "\n",
        "* *single sequence:* `<s> X </s>`\n",
        "\n",
        "* *pair of sequences:* `<s> A </s></s> B </s>`\n",
        "\n",
        "Notice the **space** at the beginning and the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SabZa-dhLxlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZRXWd0D1ALZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js5EhQa31dTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = \"Sooo SAD I will miss you here in San Diego!!!\"\n",
        "selected_text = \"Sooo SAD\"\n",
        "sentiment = \"negative\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuPUZ2j2y56c",
        "colab_type": "text"
      },
      "source": [
        "Add a space at the start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNwBGHzXqkig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = \" \" + \" \".join(str(tweet).split())\n",
        "selected_text = \" \" + \" \".join(str(selected_text).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L75TF64zCV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_start, idx_end = None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T7-XtBIzCaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comparing from index 1\n",
        "for index in (i for i, c in enumerate(tweet) if c == selected_text[1]):\n",
        "    if \" \"+tweet[index:index+len(selected_text)-1] == selected_text:\n",
        "        idx_start = index\n",
        "        idx_end = index + len(selected_text)-1\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz_aEkM7zCei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "466c43a2-849e-4462-e3ae-9ee42437fdde"
      },
      "source": [
        "idx_start, idx_end, tweet[idx_start: idx_end]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 9, 'Sooo SAD')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D54HbT0J0Qmo",
        "colab": {}
      },
      "source": [
        "intersection = [0]*len(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X7myimgP0Qm3",
        "colab": {}
      },
      "source": [
        "for idx in range(idx_start, idx_end):\n",
        "    intersection[idx] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3avarmj0UUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = ByteLevelBPETokenizer(vocab_file=\"roberta-base-vocab.json\",\n",
        "                                  merges_file=\"roberta-base-merges.txt\", \n",
        "                                  lowercase=True, add_prefix_space=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR4mDRgW0mMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = tokenizer.encode(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA_9aF4Y0mJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e69acba4-5afb-4e88-bf84-0916d616bfa9"
      },
      "source": [
        "print(f\"IDS: {enc.ids}\\n\")\n",
        "print(f\"TOKENS: {enc.tokens}\\n\")\n",
        "print(f\"OFFSET: {enc.offsets}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDS: [98, 3036, 5074, 939, 40, 2649, 47, 259, 11, 15610, 1597, 2977, 16506]\n",
            "\n",
            "TOKENS: ['Ġso', 'oo', 'Ġsad', 'Ġi', 'Ġwill', 'Ġmiss', 'Ġyou', 'Ġhere', 'Ġin', 'Ġsan', 'Ġdie', 'go', '!!!']\n",
            "\n",
            "OFFSET: [(0, 3), (3, 5), (5, 9), (9, 11), (11, 16), (16, 21), (21, 25), (25, 30), (30, 33), (33, 37), (37, 41), (41, 43), (43, 46)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N0rJ4CySVs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b0d57754-b15b-4b7c-b7f2-ee70a5a3b10a"
      },
      "source": [
        "target_idx = []\n",
        "for i, (o1, o2) in enumerate(enc.offsets):\n",
        "    if sum(intersection[o1: o2]) > 0:\n",
        "        print(o1, o2, enc.tokens[i])\n",
        "        target_idx.append(i)\n",
        "    \n",
        "target_start = target_idx[0]\n",
        "target_end = target_idx[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3 Ġso\n",
            "3 5 oo\n",
            "5 9 Ġsad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzY8ZE0d0BhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"roberta-base-vocab.json\", \"r\") as file:\n",
        "    vocab = json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEiBaO8C3T_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "13b79c4c-46c1-468e-999e-5cc81af41b4e"
      },
      "source": [
        "print(f\"Positive: {vocab['positive']}\")\n",
        "print(f\"Negative: {vocab['negative']}\")\n",
        "print(f\"Neutral: {vocab['neutral']}\")\n",
        "print(f\"BOS: {vocab['<s>']}\")\n",
        "print(f\"EOS: {vocab['</s>']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: 22173\n",
            "Negative: 33407\n",
            "Neutral: 12516\n",
            "BOS: 0\n",
            "EOS: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlwLtkCSztIe",
        "colab_type": "text"
      },
      "source": [
        "* *pair of sequences:* `<s> A </s></s> B </s>`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ms35uhMzkIy",
        "colab": {}
      },
      "source": [
        "input_ids = [0] + [sentiment_map[sentiment]] + [2] + [2] + enc.ids + [2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPzba5mf0O1U",
        "colab_type": "text"
      },
      "source": [
        "RoBERTa doesn’t have *token_type_ids*, you don’t need to indicate which token belongs to which segment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lz4uggjkzkI6",
        "colab": {}
      },
      "source": [
        "attention_mask = [1]*(len(enc.ids)+5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-T94KLEazkI_",
        "colab": {}
      },
      "source": [
        "# Offsets for [CLS] [sentiment] [SEP] followed by actual offsets & [SEP] at end\n",
        "offsets = [(0, 0), (0, 0), (0, 0), (0, 0)]+enc.offsets+[(0, 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N8deblROzkJB",
        "colab": {}
      },
      "source": [
        "target_start += 4\n",
        "target_end += 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6NL2hS1y1UcN",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 512 # hyperparameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpk3LF-y1Ucc",
        "colab": {}
      },
      "source": [
        "padding_length = MAX_LEN - len(enc.ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "es3LPe2c1Ucf",
        "colab": {}
      },
      "source": [
        "if padding_length > 0:\n",
        "    input_ids = input_ids+([1]*padding_length) # {<pad>: 1}\n",
        "    attention_mask = attention_mask+([0]*padding_length)\n",
        "    offsets = offsets+([(0, 0)]*padding_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uJn6CRA1JiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpvvM_c5Bx1",
        "colab_type": "text"
      },
      "source": [
        "## XLNET\n",
        "[Kaggle Kernel](https://www.kaggle.com/abhishek/sentencepiece-tokenizer-with-offsets/notebook)\n",
        "\n",
        "XLNET uses SentencePiece Tokenizer.\n",
        "\n",
        "* Pre-tokenization is not required\n",
        "* No language-dependent logic\n",
        "* BPE and unigram language model supported\n",
        "* Same tokenization/detokenization is obtained as long as the same model is used\n",
        "\n",
        "It has 4 components -\n",
        "* Normalizer\n",
        "* Trainer\n",
        "* Encoder\n",
        "* Decoder\n",
        "\n",
        "$$Decode(Encode(Normalize(text)))=Normalize(text)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAKEHUUEdNDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorflow_text sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVOOEoJwwpY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU6EI99VwryJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bd40cf74-c824-44a1-8c94-59cdde42921b"
      },
      "source": [
        "!unzip cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: xlnet_cased_L-12_H-768_A-12/\n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.index  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.data-00000-of-00001  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/spiece.model  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.meta  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDx4eoU25CM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = \"Sooo SAD I will miss you here in San Diego!!!\"\n",
        "selected_text = \"Sooo SAD\"\n",
        "sentiment = \"negative\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKiqhV0g5CJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsUMhCmhqc9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sentencepiece_pb2 import SentencePieceText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHFo1Xvv8Qz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentencePieceTokenizer:\n",
        "    def __init__(self, model_path):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.load(os.path.join(model_path, \"spiece.model\"))\n",
        "    \n",
        "    def encode(self, sentence):\n",
        "        spt = SentencePieceText()\n",
        "        spt.ParseFromString(self.sp.encode_as_serialized_proto(sentence))\n",
        "        tokenized_str = self.sp.encode(sentence, out_type=str)\n",
        "        offsets = []\n",
        "        tokens = []\n",
        "        for piece in spt.pieces:\n",
        "            tokens.append(piece.id)\n",
        "            offsets.append((piece.begin, piece.end))\n",
        "        return tokens, offsets, tokenized_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8keFEpSqxfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spt = SentencePieceTokenizer(model_path=\"xlnet_cased_L-12_H-768_A-12\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DJS42MXrMrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens, offsets, tokenized_str = spt.encode(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKsY3iR_rV_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e8ed7f56-6c86-417f-80b7-c2a13fc565ed"
      },
      "source": [
        "print(f\"Tokens: {tokens}\\n\")\n",
        "print(f\"Offsets: {offsets}\\n\")\n",
        "print(f\"Tokenized String: {tokenized_str}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens: [346, 5449, 4763, 417, 35, 53, 3706, 44, 193, 25, 647, 4223, 12791]\n",
            "\n",
            "Offsets: [(0, 2), (2, 4), (4, 7), (7, 8), (8, 10), (10, 15), (15, 20), (20, 24), (24, 29), (29, 32), (32, 36), (36, 42), (42, 45)]\n",
            "\n",
            "Tokenized String: ['▁So', 'oo', '▁SA', 'D', '▁I', '▁will', '▁miss', '▁you', '▁here', '▁in', '▁San', '▁Diego', '!!!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1aN8lNpp19FP",
        "colab": {}
      },
      "source": [
        "for index in (i for i, c in enumerate(tweet) if c == selected_text[0]):\n",
        "    if tweet[index:index+len(selected_text)] == selected_text:\n",
        "        idx_start = index\n",
        "        idx_end = index + len(selected_text)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FLNmiWFn19Fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e97566c-3769-4fb2-e621-bdc530b31184"
      },
      "source": [
        "idx_start, idx_end, tweet[idx_start: idx_end]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 8, 'Sooo SAD')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f1AyEidd19Fm",
        "colab": {}
      },
      "source": [
        "intersection = [0]*len(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DmgVLUlk19Ft",
        "colab": {}
      },
      "source": [
        "for idx in range(idx_start, idx_end):\n",
        "    intersection[idx] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC5wKo_Z18hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_idx = []\n",
        "for i, (o1, o2) in enumerate(offsets):\n",
        "    if sum(intersection[o1: o2]) > 0:\n",
        "        target_idx.append(i)\n",
        "    \n",
        "target_start = target_idx[0]\n",
        "target_end = target_idx[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SaqBUCdr7lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HSHheZEZSOg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "An XLNet sequence has the following format:\n",
        "\n",
        "*single sequence:* `X <sep> <cls>`\n",
        "\n",
        "*pair of sequences:* `A <sep> B <sep> <cls>`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hMgKdqnyACs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8b77d3a5-8eb6-43e8-9ebb-d7e92c32bd53"
      },
      "source": [
        "print(f\"Positive: {spt.encode('positive')[0][0]}\")\n",
        "print(f\"Negative: {spt.encode('negative')[0][0]}\")\n",
        "print(f\"Neutral: {spt.encode('neutral')[0][0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: 1654\n",
            "Negative: 2981\n",
            "Neutral: 9201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97cjbpG0OwH",
        "colab_type": "text"
      },
      "source": [
        "* `[BOS]` - 1\n",
        "* `[EOS]` - 2\n",
        "* `[CLS]` - 3\n",
        "* `[SEP]` - 4\n",
        "* `[PAD]` - 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-a5Y65A3Q8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_map = {'positive': 1654, \n",
        "                 'negative': 2981,\n",
        "                 'neutral': 9201\n",
        "                 }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vfg2NDpyAMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = tokens + [4] + [sentiment_map[sentiment]] + [4] + [3] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNwUSPM65CGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_type_ids = [1]*len(tokens)+[0]*4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6wVinSN3hea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = [1]*(len(tokens)+4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqxWYSn3haD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "offsets = offsets+[(0, 0)*4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxJDH3vR4LHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a2c0c31b-4cd2-402c-c9f8-30b7adf99208"
      },
      "source": [
        "print(f\"Input IDS: {input_ids}\\n\")\n",
        "print(f\"Input Type IDS: {token_type_ids}\\n\")\n",
        "print(f\"Offsets: {offsets}\\n\")\n",
        "print(f\"Start Target Index: {target_start}\\tEnd Target Index: {target_end}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input IDS: [346, 5449, 4763, 417, 35, 53, 3706, 44, 193, 25, 647, 4223, 12791, 4, 2981, 4, 3]\n",
            "\n",
            "Input Type IDS: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "\n",
            "Offsets: [(0, 2), (2, 4), (4, 7), (7, 8), (8, 10), (10, 15), (15, 20), (20, 24), (24, 29), (29, 32), (32, 36), (36, 42), (42, 45), (0, 0, 0, 0, 0, 0, 0, 0)]\n",
            "\n",
            "Start Target Index: 0\tEnd Target Index: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYrvB4z13j6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 192\n",
        "padding_length = MAX_LEN - len(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A0i2r573j1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if padding_length > 0:\n",
        "    input_ids = input_ids+([5]*padding_length)\n",
        "    attention_mask = attention_mask+([0]*padding_length)\n",
        "    token_type_ids = token_type_ids+([0]*padding_length)\n",
        "    offsets = offsets+([(0, 0)]*padding_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKX1-4lxUft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}