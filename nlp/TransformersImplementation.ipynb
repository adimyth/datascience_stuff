{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adimyth/datascience_stuff/blob/master/nlp/TransformersImplementation\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mm8EvwjwggXH"
   },
   "source": [
    "## Dataset\n",
    "English to Spanish Conversion - http://www.manythings.org/anki/spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aZW-uEgIf7Yy",
    "outputId": "f59a4c58-297a-49b8-e2da-b025af83374f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-05 17:19:21--  http://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:3033::6818:6dc4, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4781548 (4.6M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   4.56M  4.57MB/s    in 1.0s    \n",
      "\n",
      "2020-05-05 17:19:22 (4.57 MB/s) - ‘spa-eng.zip’ saved [4781548/4781548]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m_CfMoXrhPJ6",
    "outputId": "5934b39d-2243-4338-9486-4a2c5c864132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  spa-eng.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "     1441  2020-03-15 02:17   _about.txt\n",
      " 18493172  2020-03-15 02:17   spa.txt\n",
      "---------                     -------\n",
      " 18494613                     2 files\n",
      "Archive:  spa-eng.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: spa.txt                 \n"
     ]
    }
   ],
   "source": [
    "!unzip -l spa-eng.zip\n",
    "!unzip spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LrLwTegngpaq",
    "outputId": "cb152020-b3f2-4169-d5e1-dbfeabebc069"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm.notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d5ca571b7d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm.notebook'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import string\n",
    "from string import digits\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.layers import Dropout, LayerNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1fJc3PexqrK"
   },
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_QqGC99gz1Q"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ps65fz_BhFDN"
   },
   "outputs": [],
   "source": [
    "lines = pd.read_table('spa.txt', names=['english', 'spanish', 'attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8uNdjbIh9pS",
    "outputId": "c318dfbb-a38a-45f2-a17e-1a008e579d08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123770, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHAiIbv6kEpz"
   },
   "outputs": [],
   "source": [
    "lines = lines.drop(columns=['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyK4Ck3kiG_Q"
   },
   "outputs": [],
   "source": [
    "for col in lines.columns:\n",
    "    # lowercase\n",
    "    lines[col] = lines[col].apply(lambda x: x.lower())\n",
    "    # remove quotes\n",
    "    lines[col] = lines[col].apply(lambda x: re.sub(\"'\", \"\", x))\n",
    "    # remove punctuations\n",
    "    lines[col] = lines[col].apply(lambda x: ''.join(ch for ch in x if ch not in set(string.punctuation)))\n",
    "    # remove numbers\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    lines[col] = lines[col].apply(lambda x: x.translate(remove_digits))\n",
    "    # remove unnecessary spaces\n",
    "    lines[col] = lines[col].apply(lambda x: x.strip())\n",
    "    lines[col] = lines[col].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "    # add start & end tokens\n",
    "    lines[col] = lines[col].apply(lambda x : '<START> '+ x + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bx2190qtjvfQ"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvEJ-V-qFUtT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m70v150OlcO2"
   },
   "source": [
    "## Creating Vocabulary\n",
    "Create vocabulary of english and spanish words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MLQcyB9PiHRQ",
    "outputId": "172a7af7-a965-4cfd-a176-42a042998fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab: 13477\n"
     ]
    }
   ],
   "source": [
    "# English Vocab\n",
    "all_eng_words = set()\n",
    "for eng in lines['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "print(f\"English Vocab: {len(all_eng_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xcSjwUliiHGz",
    "outputId": "c2c6717f-9cc3-4977-f26b-a9dfdf82b160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Vocab: 27264\n"
     ]
    }
   ],
   "source": [
    "# Spanish Vocab\n",
    "all_spa_words = set()\n",
    "for spa in lines['spanish']:\n",
    "    for word in spa.split():\n",
    "        if word not in all_spa_words:\n",
    "            all_spa_words.add(word)\n",
    "print(f\"Spanish Vocab: {len(all_spa_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2OhsOMTiHEO",
    "outputId": "b27497df-b169-4745-ce16-7d240a298a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length Sentence (English): 49\n"
     ]
    }
   ],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list_eng=[]\n",
    "for l in lines['english']:\n",
    "    lenght_list_eng.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list_eng)\n",
    "print(f\"Max Length Sentence (English): {max_length_src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GAuhsphZmGMZ",
    "outputId": "b627c975-04fb-44ab-cbd6-db1c22d244f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length Sentence (Spanish): 49\n"
     ]
    }
   ],
   "source": [
    "# Max Length of target sequence\n",
    "lenght_list_spa=[]\n",
    "for l in lines['spanish']:\n",
    "    lenght_list_spa.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list_spa)\n",
    "print(f\"Max Length Sentence (Spanish): {max_length_src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CtA8nGIDocJw",
    "outputId": "57c7423c-7607-4075-91c3-a92589f19028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13477, 27264)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_spa_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_spa_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6ZJ5XICoccy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdPfVBDIo8DP"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQQJMk1wuJgo"
   },
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "900SDgTwocZl"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "btglD6y8uf-X",
    "outputId": "97b328d0-3665-4e45-e4fd-0c2eb16e0500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<END> 1\n",
      "<START> 2\n",
      "a 3\n",
      "aardvark 4\n",
      "aardvarks 5\n",
      "aaron 6\n",
      "aback 7\n",
      "abandon 8\n",
      "abandoned 9\n",
      "abandoning 10\n"
     ]
    }
   ],
   "source": [
    "n_items = take(10, input_token_index.items())\n",
    "for k,v in n_items:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FuB53Tomu-gJ",
    "outputId": "d960dda1-70a2-4517-8761-26f4918d501b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<END> 1\n",
      "<START> 2\n",
      "a 3\n",
      "aabe 4\n",
      "aah 5\n",
      "aaron 6\n",
      "abajo 7\n",
      "abandona 8\n",
      "abandonada 9\n",
      "abandonadas 10\n"
     ]
    }
   ],
   "source": [
    "n_items = take(10, target_token_index.items())\n",
    "for k,v in n_items:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUK7OCyjocXh"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mH4-8lhJocWC",
    "outputId": "c7d5b537-f1da-4ef8-b3e6-2a6a2a7e381e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51098</th>\n",
       "      <td>&lt;START&gt; i wasnt prepared for that &lt;END&gt;</td>\n",
       "      <td>&lt;START&gt; no estaba listo para ello &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>&lt;START&gt; did anybody get hurt &lt;END&gt;</td>\n",
       "      <td>&lt;START&gt; ¿alguien se hizo daño &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50382</th>\n",
       "      <td>&lt;START&gt; his sister became a doctor &lt;END&gt;</td>\n",
       "      <td>&lt;START&gt; su hermana se hizo médica &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>&lt;START&gt; watch this &lt;END&gt;</td>\n",
       "      <td>&lt;START&gt; mirad esto &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>&lt;START&gt; they gave up &lt;END&gt;</td>\n",
       "      <td>&lt;START&gt; se rindieron &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english                                  spanish\n",
       "51098   <START> i wasnt prepared for that <END>  <START> no estaba listo para ello <END>\n",
       "23986        <START> did anybody get hurt <END>      <START> ¿alguien se hizo daño <END>\n",
       "50382  <START> his sister became a doctor <END>  <START> su hermana se hizo médica <END>\n",
       "1621                   <START> watch this <END>                 <START> mirad esto <END>\n",
       "3535                 <START> they gave up <END>               <START> se rindieron <END>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj3YDPqvFWuy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7HSfC7gperL"
   },
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dEl7zSyocTe"
   },
   "outputs": [],
   "source": [
    "X, y = lines[\"english\"], lines[\"spanish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_qTGlDdocQk"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PqYa-lDxocH5",
    "outputId": "6c653b7d-1311-44b1-f2fa-fb1ed5277585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: ((99016,), (99016,))\n",
      "Testing Data: ((24754,), (24754,))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Testing Data: {X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lnJew4GFXh1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1p_YZIlPwORT"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwArMyIiwNPy"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(max_len, d_model):\n",
    "    pos_enc = np.zeros((max_len, d_model))\n",
    "\n",
    "    for pos in range(max_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            angle = pos / (np.power(10000, i/d_model))\n",
    "            pos_enc[pos][i] = np.sin(angle)\n",
    "\n",
    "            pos_enc[pos][i+1] = np.cos(angle)\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rk-xUS9wNAV"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th1uuNA7FkWT"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_padding(x):\n",
    "    x = x!=0\n",
    "    x = x[:, np.newaxis, np.newaxis, :].astype(float)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookahead_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = tf.cast(subsequent_mask, tf.int32)\n",
    "    subsequent_mask = subsequent_mask == 0\n",
    "    return tf.cast(subsequent_mask, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1365e92e8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(get_lookahead_mask(15)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = get_masked_padding(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = get_masked_padding(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the decoder input\n",
    "    look_ahead_mask = get_lookahead_mask(tar.shape[1])\n",
    "    dec_target_padding_mask = get_masked_padding(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_padding(x):\n",
    "    x = x!=0\n",
    "    x = x[:, np.newaxis, np.newaxis, :].astype(float)\n",
    "    return x\n",
    "\n",
    "def get_lookahead_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = tf.cast(subsequent_mask, tf.int32)\n",
    "    subsequent_mask = subsequent_mask == 0\n",
    "    return tf.cast(subsequent_mask, tf.float32)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(get_lookahead_mask(15)[0])\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = get_masked_padding(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = get_masked_padding(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the decoder input\n",
    "    look_ahead_mask = get_lookahead_mask(tar.shape[1])\n",
    "    dec_target_padding_mask = get_masked_padding(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8n-FuIgF6tA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N53DRttBHaLf"
   },
   "source": [
    "## SingleHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f3qEoFhHagE"
   },
   "outputs": [],
   "source": [
    "def SingleHeadAttention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    query - (batch_size, query_len, embedding_size)\n",
    "    key - (batch_size, value_len, embedding_size)\n",
    "    value - (batch_size, value_len, embedding_size)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1 - Matrix multiplication between query and key\n",
    "    # weights --> (batch_size, query_len, value_len)\n",
    "    weights = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # Step 2 - Weights Normalization\n",
    "    # weights --> (batch_size, query_len, value_len)\n",
    "    dim = key.shape[-1]\n",
    "    weights = weights/np.sqrt(dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        weights += (mask*-1e9) \n",
    "\n",
    "    # Step 3 - Softmax scores\n",
    "    # weights --> (batch_size, query_len, value_len)\n",
    "    weights = tf.nn.softmax(weights, axis=-1)\n",
    "    \n",
    "    # Step 4 - Context Vector\n",
    "    # context --> (batch_size, query_len, embedding_size)\n",
    "    context = tf.matmul(weights, value)\n",
    "    \n",
    "    return weights, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ql9XCgGlX-YW"
   },
   "source": [
    "## Custom Layers in TF\n",
    "1. A layer encapsulates both a state (the layer's \"weights\") and a transformation from inputs to outputs (a \"call\", the layer's forward pass).\n",
    "2. Layers can have non-trainable weights\n",
    "3. ***If you assign a Layer instance as attribute of another Layer, the outer layer will start tracking the weights of the inner layer.*** For example, Encoder layer below tracks the weight matrices $W_{k}, W_{q}, W_{v}$ of the MultiHeadAttention layer called within it.\n",
    "\n",
    "\n",
    "### Privileged training argument in the call method \n",
    "\n",
    "Some layers, in particular the BatchNormalization layer and the Dropout layer, have different behaviors during training and inference. For such layers, it is standard practice to expose a training (boolean) argument in the call method.\n",
    "\n",
    "By exposing this argument in call, you enable the built-in training and evaluation loops (e.g. fit) to correctly use the layer in training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktMLacUgHaql"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NrEiY2iDKKfN"
   },
   "source": [
    "## MutliHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65mcT7QAKK5m"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Step 1 - Create 4 matrix Wq, Wk, Wv\n",
    "        # creates a kernel of size [embedding_size, d_model]\n",
    "        self.Wq = Dense(d_model)\n",
    "        self.Wk = Dense(d_model)\n",
    "        self.Wv = Dense(d_model)\n",
    "        self.Wo = Dense(d_model)\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "        # Step 2 - Perform linear transformation\n",
    "        # query --> (batch_size, query_len, d_model)\n",
    "        query = self.Wq(query)\n",
    "        # key --> (batch_size, value_len, d_model)\n",
    "        key = self.Wk(key)\n",
    "        # value --> (batch_size, value_len, d_model)\n",
    "        value = self.Wv(value)\n",
    "        \n",
    "        '''\n",
    "        Step 3 - Reshape query,key and value. \n",
    "        Transform 3D matrix to 4D matrix by breaking along the last axis & then transpose.\n",
    "        '''\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        depth = self.d_model//self.num_heads\n",
    "        # query --> (batch_size, query_len, num_heads, depth)\n",
    "        query = tf.reshape(query, (query.shape[0], query.shape[1], \n",
    "                                   self.num_heads, depth))\n",
    "        # query --> (batch_size, num_heads, query_len, depth)\n",
    "        query = tf.transpose(query, (0, 2, 1, 3))\n",
    "\n",
    "        # key --> (batch_size, value_len, num_heads, depth)    \n",
    "        key = tf.reshape(key, (key.shape[0], key.shape[1], \n",
    "                               self.num_heads, depth))\n",
    "        # key --> (batch_size, num_heads, query_len, depth)\n",
    "        key = tf.transpose(key, (0, 2, 1, 3))\n",
    "\n",
    "        # value --> (batch_size, value_len, num_heads, depth)\n",
    "        value = tf.reshape(value, (value.shape[0], value.shape[1], \n",
    "                                   self.num_heads, depth))\n",
    "        # value --> (batch_size, num_heads, query_len, depth)\n",
    "        value = tf.transpose(value, (0, 2, 1, 3))\n",
    "        \n",
    "        # Step 4 - Apply ScaledDotProduct (SingleHeadAttention) on each of the heads\n",
    "        attention_weights, context_vector = SingleHeadAttention(query, key, value, mask)\n",
    "        # context_vector --> (batch_size, query_len, num_heads, depth)\n",
    "        context_vector = tf.transpose(context_vector, (0, 2, 1, 3))\n",
    "        \n",
    "        # Step 5 - Concatenate along the `num_heads` axis\n",
    "        # context_vector --> (batch_size, query_len, d_model)    \n",
    "        context_vector = tf.reshape(context_vector, \n",
    "                                    (context_vector.shape[0], context_vector.shape[1], self.d_model))\n",
    "        \n",
    "        # Step 6 - Apply linear transformation by multiplication with Wo\n",
    "        context_vector = self.Wo(context_vector)\n",
    "        return attention_weights, context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rl8AYR00KK2l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YgyLrsTKa4a"
   },
   "source": [
    "## PointWise FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88h8Ndp0KKx9"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.dense1 = Dense(dff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "    \n",
    "    def call(self, x):\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIlhi38rKKt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TfUm4XKKj8p"
   },
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8ThD0FmKkw2"
   },
   "outputs": [],
   "source": [
    "class SingleEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dff):\n",
    "        super(SingleEncoder, self).__init__()\n",
    "        self.mulitheadattn = MultiHeadAttention(num_heads, d_model)\n",
    "        self.feed_fwd_net = FeedForwardNetwork(d_model, dff)\n",
    "        self.dropout1 = Dropout(0.1)\n",
    "        self.dropout2 = Dropout(0.1)\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.layer_norm2 = LayerNormalization()\n",
    "\n",
    "    def call(self, query, key, value, training, mask):\n",
    "        # Step 1 - MultiHeadAttention\n",
    "        weights, context_vector = self.mulitheadattn(query, key, value, mask)\n",
    "        \n",
    "        # Dropout\n",
    "        context_vector = self.dropout1(context_vector, training=training)\n",
    "        \n",
    "        # Step 2 - Normalize (x+attention(x))\n",
    "        context_vector = self.layer_norm1(query+context_vector)\n",
    "        \n",
    "        # Step 3 - Pointwise FeedForward Network\n",
    "        ffn_out = self.feed_fwd_net(context_vector)\n",
    "        \n",
    "        # Dropout\n",
    "        ffn_out = self.dropout2(ffn_out, training=training)\n",
    "        \n",
    "        # Step 4 - Normalization again\n",
    "        encoder_out = self.layer_norm2(context_vector+ffn_out)\n",
    "        \n",
    "        return encoder_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsZY9hhRKktL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tb_fC_ka0yRl"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4io_2F10ywT"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, \n",
    "                 input_vocab_size, max_len):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(max_len, d_model)\n",
    "        self.pos_encoding = self.pos_encoding[np.newaxis, ...]\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.encoder_layers = [SingleEncoder(num_heads, d_model, dff) for x in range(num_heads)]\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= np.sqrt(self.d_model)\n",
    "        # embedding+pos_encoding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # calling a single encoder layer `num_heads` times\n",
    "        for single_encoder in self.encoder_layers:\n",
    "            x = single_encoder(x, x, x, training, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-YLjpOr0yrj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PaRbb2BDLBH1"
   },
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3tphdQbKkqO"
   },
   "outputs": [],
   "source": [
    "class SingleDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dff):\n",
    "        super(SingleDecoder, self).__init__()\n",
    "\n",
    "        self.mulitheadattn1 = MultiHeadAttention(num_heads, d_model)\n",
    "        self.mulitheadattn2 = MultiHeadAttention(num_heads, d_model)\n",
    "        self.feed_fwd_net = FeedForwardNetwork(d_model, dff)\n",
    "        self.dropout1 = Dropout(0.1)\n",
    "        self.dropout2 = Dropout(0.1)\n",
    "        self.dropout3 = Dropout(0.1)\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.layer_norm2 = LayerNormalization()\n",
    "        self.layer_norm3 = LayerNormalization()\n",
    "\n",
    "    def call(self, query, key, value, \n",
    "             encoder_out, look_ahead_mask, padding_mask):\n",
    "        # Step 1 - MultiHeadAttention\n",
    "        weights1, context_vector1 = self.mulitheadattn1(query, key, value, look_ahead_mask)\n",
    "        \n",
    "        # First Dropout\n",
    "        context_vector1 = self.dropout1(context_vector1)\n",
    "        \n",
    "        # Step 2 - Normalize (x+mha_attention1(x))\n",
    "        context_vector1 = self.layer_norm1(query+context_vector1)\n",
    "\n",
    "        # Step 3 - MultiHeadAttention. Here, the encoder_output is the Key & Value, \n",
    "        # while the ContextVector from previous MultiHeadAttention is Query\n",
    "        weights2, context_vector2 = self.mulitheadattn2(context_vector1, encoder_out, \n",
    "                                              encoder_out, padding_mask)\n",
    "        \n",
    "        # Second Dropout\n",
    "        context_vector2 = self.dropout2(context_vector2)\n",
    "        \n",
    "        # Step 4 - Normalize(mha_attention1(x)+mha_attention2(mha_attention1(x), encoder_output))\n",
    "        context_vector2 = self.layer_norm2(context_vector1+context_vector2)\n",
    "\n",
    "        # Step 5 - Pointwise FeedForward Network\n",
    "        ffn_out = self.feed_fwd_net(context_vector2)\n",
    "        \n",
    "        # Third Dropout\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        \n",
    "        # Step 4 - Normalization again\n",
    "        decoder_out = self.layer_norm3(context_vector2+ffn_out)\n",
    "        \n",
    "        return decoder_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--l5yfwOKkiM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOEljsu-1CY2"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5R_vrTQgKkd7"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, \n",
    "                 target_vocab_size, max_len):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(max_len, d_model)\n",
    "        self.pos_encoding = self.pos_encoding[np.newaxis, ...]\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.decoder_layers = [SingleDecoder(num_heads, d_model, dff) for x in range(num_heads)]\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= np.sqrt(self.d_model)\n",
    "        # embedding+pos_encoding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # calling a single decoder layer `num_heads` times\n",
    "        for single_decoder in self.decoder_layers:\n",
    "            x = single_decoder(x, x, x, enc_output, \n",
    "                               look_ahead_mask, padding_mask)\n",
    "           \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkgoktoEHacp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQIsZkX61gqP"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqmJrMfY1hGE"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                 target_vocab_size, num_encoder_tokens, num_decoder_tokens):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, num_encoder_tokens)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, num_decoder_tokens)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "    \n",
    "        # (batch_size, inp_seq_len, d_model)\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  \n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFC1NtOYWjPr"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "# <START> & <END> token\n",
    "input_vocab_size = num_encoder_tokens + 2\n",
    "target_vocab_size = num_decoder_tokens + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jRvuktyXEA6"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          num_encoder_tokens, \n",
    "                          num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuVmzqxqqtTQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzG-EgsEFB_C"
   },
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnS0Yh-dpv7q"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X=X_train, y=y_train, batch_size=128):\n",
    "    ''' Returns a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    # encoder input seq\n",
    "                    encoder_input_data[i, t] = input_token_index[word]\n",
    "                target_words = target_text.split()\n",
    "                for t, word in enumerate(target_words[:-1]):\n",
    "                    # decoder input seq\n",
    "                    decoder_input_data[i, t] = target_token_index[word] \n",
    "                for t, word in enumerate(target_words[1:]):\n",
    "                    # decoder output seq\n",
    "                    decoder_target_data[i, t] = target_token_index[word] \n",
    "            return (encoder_input_data, decoder_input_data, decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqjNuZ1wkyJ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSYvtNX3xsxr"
   },
   "source": [
    "## Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APu0FR-QxtaX"
   },
   "outputs": [],
   "source": [
    "crossentropy = SparseCategoricalCrossentropy(from_logits=True)\n",
    "def loss_func(targets, logits):\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ItV7xUdzjf1"
   },
   "outputs": [],
   "source": [
    "def train_func(targets, predictions):\n",
    "    acc_func = SparseCategoricalAccuracy()\n",
    "    acc = acc_func(targets, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57PhPMswyc0b"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtM989Z2xtQU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HukwM-n-FO4W"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfxTKF1Y1Q6s"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9g2bPRnx21Z7"
   },
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = generate_batch(X_train, y_train, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obI_0xP_1U_a"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((encoder_input_data, \n",
    "                                             decoder_input_data, \n",
    "                                             decoder_target_data))\n",
    "dataset = dataset.shuffle(20).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKNJfXcbuBFP"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src_seq, tar_seq_in, tar_seq_out):\n",
    "    enc_inp_mask, combined_mask, dec_inp_mask = create_masks(src_seq, \n",
    "                                                             tar_seq_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(src_seq, tar_seq_in, \n",
    "                                 True, \n",
    "                                 enc_inp_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_inp_mask)\n",
    "        loss = loss_func(tar_seq_out, predictions)\n",
    "        acc = train_func(tar_seq_out, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587,
     "referenced_widgets": [
      "3855b2eb12814df8bd6bb49dd48c3b09",
      "6f41a73b1f8849058a83590364890c33",
      "332d234812a14aeb9822197388606805",
      "6bedb9044c944da3a1717c3a07a55e9f",
      "2678294dfd744f0f81c50f97ae01875d",
      "0051608e3ce14f3397e9f7556e66ea96",
      "f4d1c93d5de141668893a4b5b095e368",
      "ab38186a3f584deb83b3998700d6319d",
      "1047384e7e044114beb9efea95e9f683",
      "ea90a2697d3b4f9bbc5b6e40143f2308",
      "a5c6de58d33940668a953ccc523b3019",
      "d90da3c6154740229c8c03ef1bc23278",
      "2dcc26f1464e4842978683be5aea39f4",
      "39b9ece7dc0b41da8f1364c2cfec1925",
      "c29273e0f5e74ed1ac93c5a4c5ac50a4",
      "9a03f377502b4f97870eae9496cc028a",
      "19e3b3ca9a33402894672d37fbce80a0",
      "b349a24678d0465194374d1924d50dac",
      "d25362f98cf44ccdad728a1af316b23b",
      "b39811df404b4671badbcca97c76df73",
      "53fbc76d54b9473db1a0e5f5a5627ac9",
      "2a5b562b1c4b43a4a9d389a53040d624",
      "e2b93720015943a2bd9fe760da97ad45",
      "e428c8d95bb749cd95e0be81ddd5c143",
      "7d0818597bba405bb142f5cbf7805663",
      "9d9d812adc2a451786a4e9fecd7a43c8",
      "ffebf578940c447ea3f5546b85ac3410",
      "5fa6cab40f824ae3825e099caaad699d",
      "3539668516024e2fa63da2d756e277a7",
      "5b47ce7b96ff4bdd9859ce4fb3861a7a",
      "3fb21a29ff83402bae26341bc9e4fe3f",
      "4f93fefccf2b4f40814eb914e0caf996"
     ]
    },
    "colab_type": "code",
    "id": "R-a2lZqYuBtJ",
    "outputId": "e5f35ced-672c-4e3e-b6c0-597b3e06be20"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3855b2eb12814df8bd6bb49dd48c3b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Loss 0.7440 Accuracy 0.0270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1047384e7e044114beb9efea95e9f683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Loss 0.7414 Accuracy 0.0253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3b3ca9a33402894672d37fbce80a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Loss 0.7215 Accuracy 0.0242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0818597bba405bb142f5cbf7805663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-178124ab681d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch} Loss {loss:.4f} Accuracy {acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-f1955b614232>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(src_seq, tar_seq_in, tar_seq_out)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                  \u001b[0menc_inp_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                  dec_inp_mask)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_seq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_seq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-123ff0392d81>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# (batch_size, inp_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-1ed692c4aaa9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# calling a single encoder layer `num_heads` times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_encoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-e81cef0ac995>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, training, mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Step 3 - Pointwise FeedForward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mffn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_fwd_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-08d212adea07>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_cast_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_about_input_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m           \u001b[0;31m# Inputs may be TensorSpecs when this function is called from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m           \u001b[0;31m# model._set_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             if (cls._abc_negative_cache_version ==\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mABCMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_invalidation_counter\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 subclass in cls._abc_negative_cache):\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for batch, (src_seq, tar_seq_in, tar_seq_out) in tqdm(enumerate(dataset.take(-1))):\n",
    "        loss, acc = train_step(src_seq, tar_seq_in, tar_seq_out)\n",
    "    print (f'Epoch {epoch} Loss {loss:.4f} Accuracy {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WW1yhhERC3c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1g7XGd4iU65rSNWSjK9ta",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "spanish-english-seq2seq-attention",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0051608e3ce14f3397e9f7556e66ea96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1047384e7e044114beb9efea95e9f683": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5c6de58d33940668a953ccc523b3019",
       "IPY_MODEL_d90da3c6154740229c8c03ef1bc23278"
      ],
      "layout": "IPY_MODEL_ea90a2697d3b4f9bbc5b6e40143f2308"
     }
    },
    "19e3b3ca9a33402894672d37fbce80a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d25362f98cf44ccdad728a1af316b23b",
       "IPY_MODEL_b39811df404b4671badbcca97c76df73"
      ],
      "layout": "IPY_MODEL_b349a24678d0465194374d1924d50dac"
     }
    },
    "2678294dfd744f0f81c50f97ae01875d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2a5b562b1c4b43a4a9d389a53040d624": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dcc26f1464e4842978683be5aea39f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "332d234812a14aeb9822197388606805": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0051608e3ce14f3397e9f7556e66ea96",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2678294dfd744f0f81c50f97ae01875d",
      "value": 1
     }
    },
    "3539668516024e2fa63da2d756e277a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3855b2eb12814df8bd6bb49dd48c3b09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_332d234812a14aeb9822197388606805",
       "IPY_MODEL_6bedb9044c944da3a1717c3a07a55e9f"
      ],
      "layout": "IPY_MODEL_6f41a73b1f8849058a83590364890c33"
     }
    },
    "39b9ece7dc0b41da8f1364c2cfec1925": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fb21a29ff83402bae26341bc9e4fe3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f93fefccf2b4f40814eb914e0caf996": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53fbc76d54b9473db1a0e5f5a5627ac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5b47ce7b96ff4bdd9859ce4fb3861a7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fa6cab40f824ae3825e099caaad699d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f93fefccf2b4f40814eb914e0caf996",
      "placeholder": "​",
      "style": "IPY_MODEL_3fb21a29ff83402bae26341bc9e4fe3f",
      "value": " 210/? [03:03&lt;00:00,  1.15it/s]"
     }
    },
    "6bedb9044c944da3a1717c3a07a55e9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab38186a3f584deb83b3998700d6319d",
      "placeholder": "​",
      "style": "IPY_MODEL_f4d1c93d5de141668893a4b5b095e368",
      "value": " 774/? [11:37&lt;00:00,  1.11it/s]"
     }
    },
    "6f41a73b1f8849058a83590364890c33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0818597bba405bb142f5cbf7805663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffebf578940c447ea3f5546b85ac3410",
       "IPY_MODEL_5fa6cab40f824ae3825e099caaad699d"
      ],
      "layout": "IPY_MODEL_9d9d812adc2a451786a4e9fecd7a43c8"
     }
    },
    "9a03f377502b4f97870eae9496cc028a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d9d812adc2a451786a4e9fecd7a43c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c6de58d33940668a953ccc523b3019": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39b9ece7dc0b41da8f1364c2cfec1925",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2dcc26f1464e4842978683be5aea39f4",
      "value": 1
     }
    },
    "ab38186a3f584deb83b3998700d6319d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b349a24678d0465194374d1924d50dac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b39811df404b4671badbcca97c76df73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e428c8d95bb749cd95e0be81ddd5c143",
      "placeholder": "​",
      "style": "IPY_MODEL_e2b93720015943a2bd9fe760da97ad45",
      "value": " 774/? [11:58&lt;00:00,  1.08it/s]"
     }
    },
    "c29273e0f5e74ed1ac93c5a4c5ac50a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d25362f98cf44ccdad728a1af316b23b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a5b562b1c4b43a4a9d389a53040d624",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53fbc76d54b9473db1a0e5f5a5627ac9",
      "value": 1
     }
    },
    "d90da3c6154740229c8c03ef1bc23278": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a03f377502b4f97870eae9496cc028a",
      "placeholder": "​",
      "style": "IPY_MODEL_c29273e0f5e74ed1ac93c5a4c5ac50a4",
      "value": " 774/? [12:04&lt;00:00,  1.07it/s]"
     }
    },
    "e2b93720015943a2bd9fe760da97ad45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e428c8d95bb749cd95e0be81ddd5c143": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea90a2697d3b4f9bbc5b6e40143f2308": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d1c93d5de141668893a4b5b095e368": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffebf578940c447ea3f5546b85ac3410": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b47ce7b96ff4bdd9859ce4fb3861a7a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3539668516024e2fa63da2d756e277a7",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
