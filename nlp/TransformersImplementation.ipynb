{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spanish-english-seq2seq-attention",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN1g7XGd4iU65rSNWSjK9ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3855b2eb12814df8bd6bb49dd48c3b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f41a73b1f8849058a83590364890c33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_332d234812a14aeb9822197388606805",
              "IPY_MODEL_6bedb9044c944da3a1717c3a07a55e9f"
            ]
          }
        },
        "6f41a73b1f8849058a83590364890c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "332d234812a14aeb9822197388606805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2678294dfd744f0f81c50f97ae01875d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0051608e3ce14f3397e9f7556e66ea96"
          }
        },
        "6bedb9044c944da3a1717c3a07a55e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4d1c93d5de141668893a4b5b095e368",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 774/? [11:37&lt;00:00,  1.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab38186a3f584deb83b3998700d6319d"
          }
        },
        "2678294dfd744f0f81c50f97ae01875d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0051608e3ce14f3397e9f7556e66ea96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4d1c93d5de141668893a4b5b095e368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab38186a3f584deb83b3998700d6319d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1047384e7e044114beb9efea95e9f683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea90a2697d3b4f9bbc5b6e40143f2308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5c6de58d33940668a953ccc523b3019",
              "IPY_MODEL_d90da3c6154740229c8c03ef1bc23278"
            ]
          }
        },
        "ea90a2697d3b4f9bbc5b6e40143f2308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5c6de58d33940668a953ccc523b3019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2dcc26f1464e4842978683be5aea39f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39b9ece7dc0b41da8f1364c2cfec1925"
          }
        },
        "d90da3c6154740229c8c03ef1bc23278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c29273e0f5e74ed1ac93c5a4c5ac50a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 774/? [12:04&lt;00:00,  1.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a03f377502b4f97870eae9496cc028a"
          }
        },
        "2dcc26f1464e4842978683be5aea39f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39b9ece7dc0b41da8f1364c2cfec1925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c29273e0f5e74ed1ac93c5a4c5ac50a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a03f377502b4f97870eae9496cc028a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19e3b3ca9a33402894672d37fbce80a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b349a24678d0465194374d1924d50dac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d25362f98cf44ccdad728a1af316b23b",
              "IPY_MODEL_b39811df404b4671badbcca97c76df73"
            ]
          }
        },
        "b349a24678d0465194374d1924d50dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d25362f98cf44ccdad728a1af316b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53fbc76d54b9473db1a0e5f5a5627ac9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a5b562b1c4b43a4a9d389a53040d624"
          }
        },
        "b39811df404b4671badbcca97c76df73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2b93720015943a2bd9fe760da97ad45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 774/? [11:58&lt;00:00,  1.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e428c8d95bb749cd95e0be81ddd5c143"
          }
        },
        "53fbc76d54b9473db1a0e5f5a5627ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a5b562b1c4b43a4a9d389a53040d624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b93720015943a2bd9fe760da97ad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e428c8d95bb749cd95e0be81ddd5c143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d0818597bba405bb142f5cbf7805663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d9d812adc2a451786a4e9fecd7a43c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffebf578940c447ea3f5546b85ac3410",
              "IPY_MODEL_5fa6cab40f824ae3825e099caaad699d"
            ]
          }
        },
        "9d9d812adc2a451786a4e9fecd7a43c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffebf578940c447ea3f5546b85ac3410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3539668516024e2fa63da2d756e277a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b47ce7b96ff4bdd9859ce4fb3861a7a"
          }
        },
        "5fa6cab40f824ae3825e099caaad699d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fb21a29ff83402bae26341bc9e4fe3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 210/? [03:03&lt;00:00,  1.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f93fefccf2b4f40814eb914e0caf996"
          }
        },
        "3539668516024e2fa63da2d756e277a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b47ce7b96ff4bdd9859ce4fb3861a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fb21a29ff83402bae26341bc9e4fe3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f93fefccf2b4f40814eb914e0caf996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adimyth/datascience_stuff/blob/master/nlp/TransformersImplementation\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8EvwjwggXH",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "English to Spanish Conversion - http://www.manythings.org/anki/spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZW-uEgIf7Yy",
        "colab_type": "code",
        "outputId": "f59a4c58-297a-49b8-e2da-b025af83374f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-05 17:19:21--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:3033::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4781548 (4.6M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   4.56M  4.57MB/s    in 1.0s    \n",
            "\n",
            "2020-05-05 17:19:22 (4.57 MB/s) - ‘spa-eng.zip’ saved [4781548/4781548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_CfMoXrhPJ6",
        "colab_type": "code",
        "outputId": "5934b39d-2243-4338-9486-4a2c5c864132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!unzip -l spa-eng.zip\n",
        "!unzip spa-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "     1441  2020-03-15 02:17   _about.txt\n",
            " 18493172  2020-03-15 02:17   spa.txt\n",
            "---------                     -------\n",
            " 18494613                     2 files\n",
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrLwTegngpaq",
        "colab_type": "code",
        "outputId": "cb152020-b3f2-4169-d5e1-dbfeabebc069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import string\n",
        "from string import digits\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense\n",
        "from tensorflow.keras.layers import Dropout, LayerNormalization\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1fJc3PexqrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_QqGC99gz1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps65fz_BhFDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = pd.read_table('spa.txt', names=['english', 'spanish', 'attributes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8uNdjbIh9pS",
        "colab_type": "code",
        "outputId": "c318dfbb-a38a-45f2-a17e-1a008e579d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123770, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHAiIbv6kEpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = lines.drop(columns=['attributes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyK4Ck3kiG_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in lines.columns:\n",
        "    # lowercase\n",
        "    lines[col] = lines[col].apply(lambda x: x.lower())\n",
        "    # remove quotes\n",
        "    lines[col] = lines[col].apply(lambda x: re.sub(\"'\", \"\", x))\n",
        "    # remove punctuations\n",
        "    lines[col] = lines[col].apply(lambda x: ''.join(ch for ch in x if ch not in set(string.punctuation)))\n",
        "    # remove numbers\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    lines[col] = lines[col].apply(lambda x: x.translate(remove_digits))\n",
        "    # remove unnecessary spaces\n",
        "    lines[col] = lines[col].apply(lambda x: x.strip())\n",
        "    lines[col] = lines[col].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "    # add start & end tokens\n",
        "    lines[col] = lines[col].apply(lambda x : '<START> '+ x + ' <END>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx2190qtjvfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvEJ-V-qFUtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m70v150OlcO2",
        "colab_type": "text"
      },
      "source": [
        "## Creating Vocabulary\n",
        "Create vocabulary of english and spanish words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLQcyB9PiHRQ",
        "colab_type": "code",
        "outputId": "172a7af7-a965-4cfd-a176-42a042998fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# English Vocab\n",
        "all_eng_words = set()\n",
        "for eng in lines['english']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "print(f\"English Vocab: {len(all_eng_words)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab: 13477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcSjwUliiHGz",
        "colab_type": "code",
        "outputId": "c2c6717f-9cc3-4977-f26b-a9dfdf82b160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Spanish Vocab\n",
        "all_spa_words = set()\n",
        "for spa in lines['spanish']:\n",
        "    for word in spa.split():\n",
        "        if word not in all_spa_words:\n",
        "            all_spa_words.add(word)\n",
        "print(f\"Spanish Vocab: {len(all_spa_words)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spanish Vocab: 27264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2OhsOMTiHEO",
        "colab_type": "code",
        "outputId": "b27497df-b169-4745-ce16-7d240a298a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list_eng=[]\n",
        "for l in lines['english']:\n",
        "    lenght_list_eng.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list_eng)\n",
        "print(f\"Max Length Sentence (English): {max_length_src}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Length Sentence (English): 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAuhsphZmGMZ",
        "colab_type": "code",
        "outputId": "b627c975-04fb-44ab-cbd6-db1c22d244f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list_spa=[]\n",
        "for l in lines['spanish']:\n",
        "    lenght_list_spa.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list_spa)\n",
        "print(f\"Max Length Sentence (Spanish): {max_length_src}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Length Sentence (Spanish): 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtA8nGIDocJw",
        "colab_type": "code",
        "outputId": "57c7423c-7607-4075-91c3-a92589f19028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_spa_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_spa_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13477, 27264)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ZJ5XICoccy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdPfVBDIo8DP",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQQJMk1wuJgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "900SDgTwocZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btglD6y8uf-X",
        "colab_type": "code",
        "outputId": "97b328d0-3665-4e45-e4fd-0c2eb16e0500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "n_items = take(10, input_token_index.items())\n",
        "for k,v in n_items:\n",
        "    print(k, v)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<END> 1\n",
            "<START> 2\n",
            "a 3\n",
            "aardvark 4\n",
            "aardvarks 5\n",
            "aaron 6\n",
            "aback 7\n",
            "abandon 8\n",
            "abandoned 9\n",
            "abandoning 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuB53Tomu-gJ",
        "colab_type": "code",
        "outputId": "d960dda1-70a2-4517-8761-26f4918d501b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "n_items = take(10, target_token_index.items())\n",
        "for k,v in n_items:\n",
        "    print(k, v)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<END> 1\n",
            "<START> 2\n",
            "a 3\n",
            "aabe 4\n",
            "aah 5\n",
            "aaron 6\n",
            "abajo 7\n",
            "abandona 8\n",
            "abandonada 9\n",
            "abandonadas 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUK7OCyjocXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH4-8lhJocWC",
        "colab_type": "code",
        "outputId": "c7d5b537-f1da-4ef8-b3e6-2a6a2a7e381e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51098</th>\n",
              "      <td>&lt;START&gt; i wasnt prepared for that &lt;END&gt;</td>\n",
              "      <td>&lt;START&gt; no estaba listo para ello &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23986</th>\n",
              "      <td>&lt;START&gt; did anybody get hurt &lt;END&gt;</td>\n",
              "      <td>&lt;START&gt; ¿alguien se hizo daño &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50382</th>\n",
              "      <td>&lt;START&gt; his sister became a doctor &lt;END&gt;</td>\n",
              "      <td>&lt;START&gt; su hermana se hizo médica &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>&lt;START&gt; watch this &lt;END&gt;</td>\n",
              "      <td>&lt;START&gt; mirad esto &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535</th>\n",
              "      <td>&lt;START&gt; they gave up &lt;END&gt;</td>\n",
              "      <td>&lt;START&gt; se rindieron &lt;END&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        english                                  spanish\n",
              "51098   <START> i wasnt prepared for that <END>  <START> no estaba listo para ello <END>\n",
              "23986        <START> did anybody get hurt <END>      <START> ¿alguien se hizo daño <END>\n",
              "50382  <START> his sister became a doctor <END>  <START> su hermana se hizo médica <END>\n",
              "1621                   <START> watch this <END>                 <START> mirad esto <END>\n",
              "3535                 <START> they gave up <END>               <START> se rindieron <END>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj3YDPqvFWuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7HSfC7gperL",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dEl7zSyocTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = lines[\"english\"], lines[\"spanish\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_qTGlDdocQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqYa-lDxocH5",
        "colab_type": "code",
        "outputId": "6c653b7d-1311-44b1-f2fa-fb1ed5277585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f\"Training Data: {X_train.shape, y_train.shape}\")\n",
        "print(f\"Testing Data: {X_test.shape, y_test.shape}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data: ((99016,), (99016,))\n",
            "Testing Data: ((24754,), (24754,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnJew4GFXh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p_YZIlPwORT",
        "colab_type": "text"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwArMyIiwNPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positional_encoding(max_len, d_model):\n",
        "    pos_enc = np.zeros((max_len, d_model))\n",
        "\n",
        "    for pos in range(max_len):\n",
        "        for i in range(0, d_model, 2):\n",
        "            angle = pos / (np.power(10000, i/d_model))\n",
        "            pos_enc[pos][i] = np.sin(angle)\n",
        "\n",
        "            pos_enc[pos][i+1] = np.cos(angle)\n",
        "    return pos_enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rk-xUS9wNAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th1uuNA7FkWT",
        "colab_type": "text"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6-yQmiwFk5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_masked_padding(x):\n",
        "    x = x==0\n",
        "    x = x[:, np.newaxis, np.newaxis, :]\n",
        "    return tf.cast(x, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_5K-M4G5lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lookahead_mask(size):\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
        "    subsequent_mask = tf.cast(subsequent_mask, tf.int32)\n",
        "    subsequent_mask = subsequent_mask == 0\n",
        "    return tf.cast(subsequent_mask, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN6ykZPcG506",
        "colab_type": "code",
        "outputId": "a50a15b0-05c5-48c6-9ea3-ec314337ed1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(get_lookahead_mask(15)[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9aba907b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrP6VdQTsWh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = get_masked_padding(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = get_masked_padding(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the decoder input\n",
        "  look_ahead_mask = get_lookahead_mask(tar.shape[1])\n",
        "  dec_target_padding_mask = get_masked_padding(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8n-FuIgF6tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N53DRttBHaLf",
        "colab_type": "text"
      },
      "source": [
        "## SingleHead Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f3qEoFhHagE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SingleHeadAttention(query, key, value, mask=None):\n",
        "    \"\"\"\n",
        "    query - (batch_size, query_len, embedding_size)\n",
        "    key - (batch_size, value_len, embedding_size)\n",
        "    value - (batch_size, value_len, embedding_size)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Step 1 - Matrix multiplication between query and key\n",
        "    # weights --> (batch_size, query_len, value_len)\n",
        "    weights = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # Step 2 - Weights Normalization\n",
        "    # weights --> (batch_size, query_len, value_len)\n",
        "    dim = key.shape[-1]\n",
        "    weights = weights/np.sqrt(dim)\n",
        "    \n",
        "    if mask is not None:\n",
        "        weights += (mask*-1e9) \n",
        "\n",
        "    # Step 3 - Softmax scores\n",
        "    # weights --> (batch_size, query_len, value_len)\n",
        "    weights = tf.nn.softmax(weights, axis=-1)\n",
        "    \n",
        "    # Step 4 - Context Vector\n",
        "    # context --> (batch_size, query_len, embedding_size)\n",
        "    context = tf.matmul(weights, value)\n",
        "    \n",
        "    return weights, context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql9XCgGlX-YW",
        "colab_type": "text"
      },
      "source": [
        "## Custom Layers in TF\n",
        "1. A layer encapsulates both a state (the layer's \"weights\") and a transformation from inputs to outputs (a \"call\", the layer's forward pass).\n",
        "2. Layers can have non-trainable weights\n",
        "3. ***If you assign a Layer instance as attribute of another Layer, the outer layer will start tracking the weights of the inner layer.*** For example, Encoder layer below tracks the weight matrices $W_{k}, W_{q}, W_{v}$ of the MultiHeadAttention layer called within it.\n",
        "\n",
        "\n",
        "### Privileged training argument in the call method \n",
        "\n",
        "Some layers, in particular the BatchNormalization layer and the Dropout layer, have different behaviors during training and inference. For such layers, it is standard practice to expose a training (boolean) argument in the call method.\n",
        "\n",
        "By exposing this argument in call, you enable the built-in training and evaluation loops (e.g. fit) to correctly use the layer in training and inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktMLacUgHaql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrEiY2iDKKfN",
        "colab_type": "text"
      },
      "source": [
        "## MutliHead Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mcT7QAKK5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, d_model):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Step 1 - Create 4 matrix Wq, Wk, Wv\n",
        "        # creates a kernel of size [embedding_size, d_model]\n",
        "        self.Wq = Dense(d_model)\n",
        "        self.Wk = Dense(d_model)\n",
        "        self.Wv = Dense(d_model)\n",
        "        self.Wo = Dense(d_model)\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "    \n",
        "    def call(self, query, key, value, mask):\n",
        "        # Step 2 - Perform linear transformation\n",
        "        # query --> (batch_size, query_len, d_model)\n",
        "        query = self.Wq(query)\n",
        "        # key --> (batch_size, value_len, d_model)\n",
        "        key = self.Wk(key)\n",
        "        # value --> (batch_size, value_len, d_model)\n",
        "        value = self.Wv(value)\n",
        "        \n",
        "        '''\n",
        "        Step 3 - Reshape query,key and value. \n",
        "        Transform 3D matrix to 4D matrix by breaking along the last axis & then transpose.\n",
        "        '''\n",
        "        assert self.d_model % self.num_heads == 0\n",
        "        depth = self.d_model//self.num_heads\n",
        "        # query --> (batch_size, query_len, num_heads, depth)\n",
        "        query = tf.reshape(query, (query.shape[0], query.shape[1], \n",
        "                                   self.num_heads, depth))\n",
        "        # query --> (batch_size, num_heads, query_len, depth)\n",
        "        query = tf.transpose(query, (0, 2, 1, 3))\n",
        "\n",
        "        # key --> (batch_size, value_len, num_heads, depth)    \n",
        "        key = tf.reshape(key, (key.shape[0], key.shape[1], \n",
        "                               self.num_heads, depth))\n",
        "        # key --> (batch_size, num_heads, query_len, depth)\n",
        "        key = tf.transpose(key, (0, 2, 1, 3))\n",
        "\n",
        "        # value --> (batch_size, value_len, num_heads, depth)\n",
        "        value = tf.reshape(value, (value.shape[0], value.shape[1], \n",
        "                                   self.num_heads, depth))\n",
        "        # value --> (batch_size, num_heads, query_len, depth)\n",
        "        value = tf.transpose(value, (0, 2, 1, 3))\n",
        "        \n",
        "        # Step 4 - Apply ScaledDotProduct (SingleHeadAttention) on each of the heads\n",
        "        attention_weights, context_vector = SingleHeadAttention(query, key, value, mask)\n",
        "        # context_vector --> (batch_size, query_len, num_heads, depth)\n",
        "        context_vector = tf.transpose(context_vector, (0, 2, 1, 3))\n",
        "        \n",
        "        # Step 5 - Concatenate along the `num_heads` axis\n",
        "        # context_vector --> (batch_size, query_len, d_model)    \n",
        "        context_vector = tf.reshape(context_vector, \n",
        "                                    (context_vector.shape[0], context_vector.shape[1], self.d_model))\n",
        "        \n",
        "        # Step 6 - Apply linear transformation by multiplication with Wo\n",
        "        context_vector = self.Wo(context_vector)\n",
        "        return attention_weights, context_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl8AYR00KK2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YgyLrsTKa4a",
        "colab_type": "text"
      },
      "source": [
        "## PointWise FeedForward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88h8Ndp0KKx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, dff):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.dense1 = Dense(dff, activation='relu')\n",
        "        self.dense2 = Dense(d_model)\n",
        "    \n",
        "    def call(self, x):\n",
        "        out = self.dense1(x)\n",
        "        out = self.dense2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIlhi38rKKt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TfUm4XKKj8p",
        "colab_type": "text"
      },
      "source": [
        "## Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ThD0FmKkw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SingleEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, d_model, dff):\n",
        "        super(SingleEncoder, self).__init__()\n",
        "        self.mulitheadattn = MultiHeadAttention(num_heads, d_model)\n",
        "        self.feed_fwd_net = FeedForwardNetwork(d_model, dff)\n",
        "        self.dropout1 = Dropout(0.1)\n",
        "        self.dropout2 = Dropout(0.1)\n",
        "        self.layer_norm1 = LayerNormalization()\n",
        "        self.layer_norm2 = LayerNormalization()\n",
        "\n",
        "    def call(self, query, key, value, training, mask):\n",
        "        # Step 1 - MultiHeadAttention\n",
        "        weights, context_vector = self.mulitheadattn(query, key, value, mask)\n",
        "        \n",
        "        # Dropout\n",
        "        context_vector = self.dropout1(context_vector, training=training)\n",
        "        \n",
        "        # Step 2 - Normalize (x+attention(x))\n",
        "        context_vector = self.layer_norm1(query+context_vector)\n",
        "        \n",
        "        # Step 3 - Pointwise FeedForward Network\n",
        "        ffn_out = self.feed_fwd_net(context_vector)\n",
        "        \n",
        "        # Dropout\n",
        "        ffn_out = self.dropout2(ffn_out, training=training)\n",
        "        \n",
        "        # Step 4 - Normalization again\n",
        "        encoder_out = self.layer_norm2(context_vector+ffn_out)\n",
        "        \n",
        "        return encoder_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsZY9hhRKktL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb_fC_ka0yRl",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4io_2F10ywT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, \n",
        "                 input_vocab_size, max_len):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_len, d_model)\n",
        "        self.pos_encoding = self.pos_encoding[np.newaxis, ...]\n",
        "        self.dropout = Dropout(0.1)\n",
        "        self.encoder_layers = [SingleEncoder(num_heads, d_model, dff) for x in range(num_heads)]\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= np.sqrt(self.d_model)\n",
        "        # embedding+pos_encoding\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # calling a single encoder layer `num_heads` times\n",
        "        for single_encoder in self.encoder_layers:\n",
        "            x = single_encoder(x, x, x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-YLjpOr0yrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaRbb2BDLBH1",
        "colab_type": "text"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3tphdQbKkqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SingleDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, d_model, dff):\n",
        "        super(SingleDecoder, self).__init__()\n",
        "\n",
        "        self.mulitheadattn1 = MultiHeadAttention(num_heads, d_model)\n",
        "        self.mulitheadattn2 = MultiHeadAttention(num_heads, d_model)\n",
        "        self.feed_fwd_net = FeedForwardNetwork(d_model, dff)\n",
        "        self.dropout1 = Dropout(0.1)\n",
        "        self.dropout2 = Dropout(0.1)\n",
        "        self.dropout3 = Dropout(0.1)\n",
        "        self.layer_norm1 = LayerNormalization()\n",
        "        self.layer_norm2 = LayerNormalization()\n",
        "        self.layer_norm3 = LayerNormalization()\n",
        "\n",
        "    def call(self, query, key, value, \n",
        "             encoder_out, look_ahead_mask, padding_mask):\n",
        "        # Step 1 - MultiHeadAttention\n",
        "        weights1, context_vector1 = self.mulitheadattn1(query, key, value, look_ahead_mask)\n",
        "        \n",
        "        # First Dropout\n",
        "        context_vector1 = self.dropout1(context_vector1)\n",
        "        \n",
        "        # Step 2 - Normalize (x+mha_attention1(x))\n",
        "        context_vector1 = self.layer_norm1(query+context_vector1)\n",
        "\n",
        "        # Step 3 - MultiHeadAttention. Here, the encoder_output is the Key & Value, \n",
        "        # while the ContextVector from previous MultiHeadAttention is Query\n",
        "        weights2, context_vector2 = self.mulitheadattn2(context_vector1, encoder_out, \n",
        "                                              encoder_out, padding_mask)\n",
        "        \n",
        "        # Second Dropout\n",
        "        context_vector2 = self.dropout2(context_vector2)\n",
        "        \n",
        "        # Step 4 - Normalize(mha_attention1(x)+mha_attention2(mha_attention1(x), encoder_output))\n",
        "        context_vector2 = self.layer_norm2(context_vector1+context_vector2)\n",
        "\n",
        "        # Step 5 - Pointwise FeedForward Network\n",
        "        ffn_out = self.feed_fwd_net(context_vector2)\n",
        "        \n",
        "        # Third Dropout\n",
        "        ffn_out = self.dropout3(ffn_out)\n",
        "        \n",
        "        # Step 4 - Normalization again\n",
        "        decoder_out = self.layer_norm3(context_vector2+ffn_out)\n",
        "        \n",
        "        return decoder_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--l5yfwOKkiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOEljsu-1CY2",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_vrTQgKkd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, \n",
        "                 target_vocab_size, max_len):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.embedding = Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_len, d_model)\n",
        "        self.pos_encoding = self.pos_encoding[np.newaxis, ...]\n",
        "        self.dropout = Dropout(0.1)\n",
        "        self.decoder_layers = [SingleDecoder(num_heads, d_model, dff) for x in range(num_heads)]\n",
        "        \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= np.sqrt(self.d_model)\n",
        "        # embedding+pos_encoding\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # calling a single decoder layer `num_heads` times\n",
        "        for single_decoder in self.decoder_layers:\n",
        "            x = single_decoder(x, x, x, enc_output, \n",
        "                               look_ahead_mask, padding_mask)\n",
        "           \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkgoktoEHacp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIsZkX61gqP",
        "colab_type": "text"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqmJrMfY1hGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "                 target_vocab_size, num_encoder_tokens, num_decoder_tokens):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, num_encoder_tokens)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, num_decoder_tokens)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, \n",
        "             look_ahead_mask, dec_padding_mask):\n",
        "    \n",
        "        # (batch_size, inp_seq_len, d_model)\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  \n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        # (batch_size, tar_seq_len, target_vocab_size)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFC1NtOYWjPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "# <START> & <END> token\n",
        "input_vocab_size = num_encoder_tokens + 2\n",
        "target_vocab_size = num_decoder_tokens + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jRvuktyXEA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          num_encoder_tokens, \n",
        "                          num_decoder_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuVmzqxqqtTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzG-EgsEFB_C",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnS0Yh-dpv7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(X=X_train, y=y_train, batch_size=128):\n",
        "    ''' Returns a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    # encoder input seq\n",
        "                    encoder_input_data[i, t] = input_token_index[word]\n",
        "                target_words = target_text.split()\n",
        "                for t, word in enumerate(target_words[:-1]):\n",
        "                    # decoder input seq\n",
        "                    decoder_input_data[i, t] = target_token_index[word] \n",
        "                for t, word in enumerate(target_words[1:]):\n",
        "                    # decoder output seq\n",
        "                    decoder_target_data[i, t] = target_token_index[word] \n",
        "            return (encoder_input_data, decoder_input_data, decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqjNuZ1wkyJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSYvtNX3xsxr",
        "colab_type": "text"
      },
      "source": [
        "## Loss & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APu0FR-QxtaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crossentropy = SparseCategoricalCrossentropy(from_logits=True)\n",
        "def loss_func(targets, logits):\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ItV7xUdzjf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_func(targets, predictions):\n",
        "    acc_func = SparseCategoricalAccuracy()\n",
        "    acc = acc_func(targets, predictions)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PhPMswyc0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtM989Z2xtQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HukwM-n-FO4W",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfxTKF1Y1Q6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g2bPRnx21Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data, decoder_input_data, decoder_target_data = generate_batch(X_train, y_train, len(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obI_0xP_1U_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((encoder_input_data, \n",
        "                                             decoder_input_data, \n",
        "                                             decoder_target_data))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKNJfXcbuBFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(src_seq, tar_seq_in, tar_seq_out):\n",
        "    enc_inp_mask, combined_mask, dec_inp_mask = create_masks(src_seq, \n",
        "                                                             tar_seq_in)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = transformer(src_seq, tar_seq_in, \n",
        "                                 True, \n",
        "                                 enc_inp_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_inp_mask)\n",
        "        loss = loss_func(tar_seq_out, predictions)\n",
        "        acc = train_func(tar_seq_out, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    return loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-a2lZqYuBtJ",
        "colab_type": "code",
        "outputId": "e5f35ced-672c-4e3e-b6c0-597b3e06be20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "3855b2eb12814df8bd6bb49dd48c3b09",
            "6f41a73b1f8849058a83590364890c33",
            "332d234812a14aeb9822197388606805",
            "6bedb9044c944da3a1717c3a07a55e9f",
            "2678294dfd744f0f81c50f97ae01875d",
            "0051608e3ce14f3397e9f7556e66ea96",
            "f4d1c93d5de141668893a4b5b095e368",
            "ab38186a3f584deb83b3998700d6319d",
            "1047384e7e044114beb9efea95e9f683",
            "ea90a2697d3b4f9bbc5b6e40143f2308",
            "a5c6de58d33940668a953ccc523b3019",
            "d90da3c6154740229c8c03ef1bc23278",
            "2dcc26f1464e4842978683be5aea39f4",
            "39b9ece7dc0b41da8f1364c2cfec1925",
            "c29273e0f5e74ed1ac93c5a4c5ac50a4",
            "9a03f377502b4f97870eae9496cc028a",
            "19e3b3ca9a33402894672d37fbce80a0",
            "b349a24678d0465194374d1924d50dac",
            "d25362f98cf44ccdad728a1af316b23b",
            "b39811df404b4671badbcca97c76df73",
            "53fbc76d54b9473db1a0e5f5a5627ac9",
            "2a5b562b1c4b43a4a9d389a53040d624",
            "e2b93720015943a2bd9fe760da97ad45",
            "e428c8d95bb749cd95e0be81ddd5c143",
            "7d0818597bba405bb142f5cbf7805663",
            "9d9d812adc2a451786a4e9fecd7a43c8",
            "ffebf578940c447ea3f5546b85ac3410",
            "5fa6cab40f824ae3825e099caaad699d",
            "3539668516024e2fa63da2d756e277a7",
            "5b47ce7b96ff4bdd9859ce4fb3861a7a",
            "3fb21a29ff83402bae26341bc9e4fe3f",
            "4f93fefccf2b4f40814eb914e0caf996"
          ]
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for batch, (src_seq, tar_seq_in, tar_seq_out) in tqdm(enumerate(dataset.take(-1))):\n",
        "        loss, acc = train_step(src_seq, tar_seq_in, tar_seq_out)\n",
        "    print (f'Epoch {epoch} Loss {loss:.4f} Accuracy {acc:.4f}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3855b2eb12814df8bd6bb49dd48c3b09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0 Loss 0.7440 Accuracy 0.0270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1047384e7e044114beb9efea95e9f683",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Loss 0.7414 Accuracy 0.0253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e3b3ca9a33402894672d37fbce80a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Loss 0.7215 Accuracy 0.0242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d0818597bba405bb142f5cbf7805663",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-178124ab681d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch} Loss {loss:.4f} Accuracy {acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-f1955b614232>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(src_seq, tar_seq_in, tar_seq_out)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                  \u001b[0menc_inp_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                  dec_inp_mask)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_seq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_seq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-123ff0392d81>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# (batch_size, inp_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-1ed692c4aaa9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# calling a single encoder layer `num_heads` times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_encoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e81cef0ac995>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, training, mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Step 3 - Pointwise FeedForward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mffn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_fwd_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-08d212adea07>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_cast_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_about_input_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m           \u001b[0;31m# Inputs may be TensorSpecs when this function is called from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m           \u001b[0;31m# model._set_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             if (cls._abc_negative_cache_version ==\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mABCMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_invalidation_counter\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 subclass in cls._abc_negative_cache):\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW1yhhERC3c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}